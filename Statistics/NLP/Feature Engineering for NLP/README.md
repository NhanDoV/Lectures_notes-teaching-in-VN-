## Course Description
In this course, you will learn techniques that will allow you to extract useful information from text and process them into a format suitable for applying ML models. 

More specifically, you will learn about `POS tagging`, `named entity recognition`, `readability scores`, the `n-gram` and `tf-idf` models, and how to implement them using `scikit-learn` and spaCy. You will also learn to compute how similar two documents are to each other. In the process, you will predict the sentiment of movie reviews and build movie and `Ted Talk` recommenders.

Following the course, you will be able to engineer critical features out of any text and solve some of the most challenging problems in `data science`!

### Chapter 1. Basic features and readability scores
Learn to compute basic features such as number of words, number of characters, average word length and number of special characters (such as `Twitter` hashtags and mentions). 

You will also learn to compute readability scores and determine the amount of education required to comprehend a piece of text.

### Chapter 2. Text preprocessing, `POS` tagging and `NER`
In this chapter, you will learn about tokenization and lemmatization. 

You will then learn how to perform text cleaning, part-of-speech tagging, and named entity recognition using the `spaCy` library. 

Upon mastering these concepts, you will proceed to make the Gettysburg address machine-friendly, analyze noun usage in fake news, and identify people mentioned in a `TechCrunch` article.

### Chapter 3. `N-Gram models`
Learn about n-gram modeling and use it to perform sentiment analysis on movie reviews.

### Chapter 4. `TF-IDF` and `similarity scores`
Learn how to compute `tf-idf` weights and the cosine similarity score between two vectors. 

You will use these concepts to build a movie and a `TED Talk` recommender. 

Finally, you will also learn about `word embeddings` and using word vector representations, you will compute similarities between various `Pink Floyd` songs.
