{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":260807,"sourceType":"datasetVersion","datasetId":109196}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h2o\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-04T05:09:13.446621Z","iopub.execute_input":"2024-03-04T05:09:13.447167Z","iopub.status.idle":"2024-03-04T05:09:17.533768Z","shell.execute_reply.started":"2024-03-04T05:09:13.447132Z","shell.execute_reply":"2024-03-04T05:09:17.532480Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Overview\n[Reference](https://github.com/NhanDoV/Lectures_notes-teaching-in-VN-/blob/master/h2o_AutoML/classification/clf-tradml-vs-automl.ipynb)","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndf = sns.load_dataset(\"titanic\")\n\ndf.fillna(value={\"age\": int(df[\"age\"].median())}, inplace=True)\ndf['survived'] = df['survived'].replace({0: 'dead', 1:'alived'})\ndf = df.dropna(axis=0, subset='embark_town')\ndf['alone'] = df['alone'].astype(str)\ndf['age'] = df['age'].astype(int)\n\nfor col in ['fare', 'age', 'parch']:\n    print(f\"Survived aggregation on class & {col}\")\n    display(pd.pivot_table(df, index='class', columns='survived', values=col, aggfunc=['mean', 'max']))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:17.536164Z","iopub.execute_input":"2024-03-04T05:09:17.536807Z","iopub.status.idle":"2024-03-04T05:09:18.416372Z","shell.execute_reply.started":"2024-03-04T05:09:17.536766Z","shell.execute_reply":"2024-03-04T05:09:18.414989Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Survived aggregation on class & fare\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               mean                  max        \nsurvived     alived       dead    alived    dead\nclass                                           \nFirst     95.840984  64.684007  512.3292  263.00\nSecond    22.055700  19.412328   65.0000   73.50\nThird     13.694887  13.669364   56.4958   69.55","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">mean</th>\n      <th colspan=\"2\" halign=\"left\">max</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th>alived</th>\n      <th>dead</th>\n      <th>alived</th>\n      <th>dead</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>First</th>\n      <td>95.840984</td>\n      <td>64.684007</td>\n      <td>512.3292</td>\n      <td>263.00</td>\n    </tr>\n    <tr>\n      <th>Second</th>\n      <td>22.055700</td>\n      <td>19.412328</td>\n      <td>65.0000</td>\n      <td>73.50</td>\n    </tr>\n    <tr>\n      <th>Third</th>\n      <td>13.694887</td>\n      <td>13.669364</td>\n      <td>56.4958</td>\n      <td>69.55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Survived aggregation on class & age\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"               mean               max     \nsurvived     alived       dead alived dead\nclass                                     \nFirst     34.373134  40.550000     80   71\nSecond    25.965517  33.134021     62   70\nThird     22.731092  26.932796     63   74","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">mean</th>\n      <th colspan=\"2\" halign=\"left\">max</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th>alived</th>\n      <th>dead</th>\n      <th>alived</th>\n      <th>dead</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>First</th>\n      <td>34.373134</td>\n      <td>40.550000</td>\n      <td>80</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>Second</th>\n      <td>25.965517</td>\n      <td>33.134021</td>\n      <td>62</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>Third</th>\n      <td>22.731092</td>\n      <td>26.932796</td>\n      <td>63</td>\n      <td>74</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Survived aggregation on class & parch\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"              mean              max     \nsurvived    alived      dead alived dead\nclass                                   \nFirst     0.395522  0.300000      2    4\nSecond    0.643678  0.144330      3    2\nThird     0.420168  0.384409      5    6","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"2\" halign=\"left\">mean</th>\n      <th colspan=\"2\" halign=\"left\">max</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th>alived</th>\n      <th>dead</th>\n      <th>alived</th>\n      <th>dead</th>\n    </tr>\n    <tr>\n      <th>class</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>First</th>\n      <td>0.395522</td>\n      <td>0.300000</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Second</th>\n      <td>0.643678</td>\n      <td>0.144330</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Third</th>\n      <td>0.420168</td>\n      <td>0.384409</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Feature engineering\nIn this session, we will try to verify the affect of bin-group from the numerical variables (`age`, `fare`) to the response `survived`","metadata":{}},{"cell_type":"code","source":"df['age_group'] = pd.cut(df['age'], bins=5)\ndf['faregroup'] = pd.cut(df['fare'], bins=5)\nfor col in ['class', 'sex', 'embark_town', 'alone', 'age_group', 'faregroup']:\n    display(pd.pivot_table(df, index='survived', columns=col, values='alive', aggfunc='count'))","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:18.418390Z","iopub.execute_input":"2024-03-04T05:09:18.419195Z","iopub.status.idle":"2024-03-04T05:09:18.553250Z","shell.execute_reply.started":"2024-03-04T05:09:18.419147Z","shell.execute_reply":"2024-03-04T05:09:18.552019Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"class     First  Second  Third\nsurvived                      \nalived      134      87    119\ndead         80      97    372","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>class</th>\n      <th>First</th>\n      <th>Second</th>\n      <th>Third</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>134</td>\n      <td>87</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>80</td>\n      <td>97</td>\n      <td>372</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sex       female  male\nsurvived              \nalived       231   109\ndead          81   468","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>sex</th>\n      <th>female</th>\n      <th>male</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>231</td>\n      <td>109</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>81</td>\n      <td>468</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"embark_town  Cherbourg  Queenstown  Southampton\nsurvived                                       \nalived              93          30          217\ndead                75          47          427","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>embark_town</th>\n      <th>Cherbourg</th>\n      <th>Queenstown</th>\n      <th>Southampton</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>93</td>\n      <td>30</td>\n      <td>217</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>75</td>\n      <td>47</td>\n      <td>427</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"alone     False  True\nsurvived             \nalived      179   161\ndead        175   374","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>alone</th>\n      <th>False</th>\n      <th>True</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>179</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>175</td>\n      <td>374</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"age_group  (-0.08, 16.0]  (16.0, 32.0]  (32.0, 48.0]  (48.0, 64.0]  \\\nsurvived                                                             \nalived                55           181            74            29   \ndead                  45           344           111            39   \n\nage_group  (64.0, 80.0]  \nsurvived                 \nalived                1  \ndead                 10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>age_group</th>\n      <th>(-0.08, 16.0]</th>\n      <th>(16.0, 32.0]</th>\n      <th>(32.0, 48.0]</th>\n      <th>(48.0, 64.0]</th>\n      <th>(64.0, 80.0]</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>55</td>\n      <td>181</td>\n      <td>74</td>\n      <td>29</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>45</td>\n      <td>344</td>\n      <td>111</td>\n      <td>39</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"faregroup  (-0.512, 102.466]  (102.466, 204.932]  (204.932, 307.398]  \\\nsurvived                                                               \nalived                   301                  25                  11   \ndead                     535                   8                   6   \n\nfaregroup  (307.398, 409.863]  (409.863, 512.329]  \nsurvived                                           \nalived                      0                   3  \ndead                        0                   0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>faregroup</th>\n      <th>(-0.512, 102.466]</th>\n      <th>(102.466, 204.932]</th>\n      <th>(204.932, 307.398]</th>\n      <th>(307.398, 409.863]</th>\n      <th>(409.863, 512.329]</th>\n    </tr>\n    <tr>\n      <th>survived</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alived</th>\n      <td>301</td>\n      <td>25</td>\n      <td>11</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>dead</th>\n      <td>535</td>\n      <td>8</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"There is not any difference between each bin-group to the final-output hence the `bingroup` are not neccessary here (`age_group` and `faregroup`)","metadata":{}},{"cell_type":"code","source":"y = df[['sex','embark_town','survived']]\nX = df.drop(columns=[\"survived\", \"alive\", \"pclass\", \"age_group\", \"faregroup\", \"parch\", \n                     \"who\", \"sibsp\", \"adult_male\", \"deck\", \"embarked\"])\nX_train, X_valid, y_train, y_valid = train_test_split(X.drop(columns=['sex','embark_town']), y, test_size=0.3, \n                                                      stratify=y, \n                                                      random_state=42)\ndf_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\ndf_valid = pd.concat([X_valid, y_valid], axis=1).reset_index(drop=True)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:18.556047Z","iopub.execute_input":"2024-03-04T05:09:18.557348Z","iopub.status.idle":"2024-03-04T05:09:18.593648Z","shell.execute_reply.started":"2024-03-04T05:09:18.557287Z","shell.execute_reply":"2024-03-04T05:09:18.592397Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   age     fare   class  alone     sex  embark_town survived\n0   20   7.8542   Third   True    male  Southampton     dead\n1   28  25.4667   Third  False  female  Southampton     dead\n2   21   7.8542   Third   True    male  Southampton     dead\n3   28   7.3125   Third   True    male  Southampton     dead\n4   36  13.0000  Second   True  female  Southampton   alived","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>fare</th>\n      <th>class</th>\n      <th>alone</th>\n      <th>sex</th>\n      <th>embark_town</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>7.8542</td>\n      <td>Third</td>\n      <td>True</td>\n      <td>male</td>\n      <td>Southampton</td>\n      <td>dead</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28</td>\n      <td>25.4667</td>\n      <td>Third</td>\n      <td>False</td>\n      <td>female</td>\n      <td>Southampton</td>\n      <td>dead</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>7.8542</td>\n      <td>Third</td>\n      <td>True</td>\n      <td>male</td>\n      <td>Southampton</td>\n      <td>dead</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>7.3125</td>\n      <td>Third</td>\n      <td>True</td>\n      <td>male</td>\n      <td>Southampton</td>\n      <td>dead</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36</td>\n      <td>13.0000</td>\n      <td>Second</td>\n      <td>True</td>\n      <td>female</td>\n      <td>Southampton</td>\n      <td>alived</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Initialize `h2o`","metadata":{}},{"cell_type":"code","source":"h2o.init()","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:18.595052Z","iopub.execute_input":"2024-03-04T05:09:18.595481Z","iopub.status.idle":"2024-03-04T05:09:27.517976Z","shell.execute_reply.started":"2024-03-04T05:09:18.595442Z","shell.execute_reply":"2024-03-04T05:09:27.516527Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Checking whether there is an H2O instance running at http://localhost:54321..... not found.\nAttempting to start a local H2O server...\n  Java Version: openjdk version \"11.0.21\" 2023-10-17; OpenJDK Runtime Environment (build 11.0.21+9-post-Ubuntu-0ubuntu120.04); OpenJDK 64-Bit Server VM (build 11.0.21+9-post-Ubuntu-0ubuntu120.04, mixed mode, sharing)\n  Starting server from /opt/conda/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n  Ice root: /tmp/tmpex4e4p8c\n  JVM stdout: /tmp/tmpex4e4p8c/h2o_unknownUser_started_from_python.out\n  JVM stderr: /tmp/tmpex4e4p8c/h2o_unknownUser_started_from_python.err\n  Server is running at http://127.0.0.1:54321\nConnecting to H2O server at http://127.0.0.1:54321 ... successful.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"--------------------------  ----------------------------------\nH2O_cluster_uptime:         03 secs\nH2O_cluster_timezone:       Etc/UTC\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.44.0.3\nH2O_cluster_version_age:    2 months and 12 days\nH2O_cluster_name:           H2O_from_python_unknownUser_cpdqd7\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    7.500 Gb\nH2O_cluster_total_cores:    4\nH2O_cluster_allowed_cores:  4\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://127.0.0.1:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nPython_version:             3.10.13 final\n--------------------------  ----------------------------------","text/html":"\n<style>\n\n#h2o-table-1.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-1 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-1 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-1 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-1 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-1 .h2o-table th,\n#h2o-table-1 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-1 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-1\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption></caption>\n    <thead></thead>\n    <tbody><tr><td>H2O_cluster_uptime:</td>\n<td>03 secs</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Etc/UTC</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.44.0.3</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>2 months and 12 days</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_unknownUser_cpdqd7</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>7.500 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>4</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://127.0.0.1:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>Python_version:</td>\n<td>3.10.13 final</td></tr></tbody>\n  </table>\n</div>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"Transform this to h2o-frame","metadata":{}},{"cell_type":"code","source":"h2o_train_df = h2o.H2OFrame(df_train)\nh2o_valid_df = h2o.H2OFrame(df_valid)\nh2o_train_df","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:27.522353Z","iopub.execute_input":"2024-03-04T05:09:27.524290Z","iopub.status.idle":"2024-03-04T05:09:28.950684Z","shell.execute_reply.started":"2024-03-04T05:09:27.524240Z","shell.execute_reply":"2024-03-04T05:09:28.948443Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\nParse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"  age     fare  class    alone    sex     embark_town    survived\n-----  -------  -------  -------  ------  -------------  ----------\n   20   7.8542  Third    True     male    Southampton    dead\n   28  25.4667  Third    False    female  Southampton    dead\n   21   7.8542  Third    True     male    Southampton    dead\n   28   7.3125  Third    True     male    Southampton    dead\n   36  13       Second   True     female  Southampton    alived\n   31  26.25    Second   False    male    Southampton    dead\n   49  56.9292  First    False    male    Cherbourg      alived\n   23   7.2292  Third    True     male    Cherbourg      dead\n   25  30       Second   False    female  Southampton    alived\n    7  29.125   Third    False    male    Queenstown     dead\n[622 rows x 7 columns]\n","text/html":"<table class='dataframe'>\n<thead>\n<tr><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">   fare</th><th>class  </th><th>alone  </th><th>sex   </th><th>embark_town  </th><th>survived  </th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\"> 7.8542</td><td>Third  </td><td>True   </td><td>male  </td><td>Southampton  </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\">25.4667</td><td>Third  </td><td>False  </td><td>female</td><td>Southampton  </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   21</td><td style=\"text-align: right;\"> 7.8542</td><td>Third  </td><td>True   </td><td>male  </td><td>Southampton  </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\"> 7.3125</td><td>Third  </td><td>True   </td><td>male  </td><td>Southampton  </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   36</td><td style=\"text-align: right;\">13     </td><td>Second </td><td>True   </td><td>female</td><td>Southampton  </td><td>alived    </td></tr>\n<tr><td style=\"text-align: right;\">   31</td><td style=\"text-align: right;\">26.25  </td><td>Second </td><td>False  </td><td>male  </td><td>Southampton  </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   49</td><td style=\"text-align: right;\">56.9292</td><td>First  </td><td>False  </td><td>male  </td><td>Cherbourg    </td><td>alived    </td></tr>\n<tr><td style=\"text-align: right;\">   23</td><td style=\"text-align: right;\"> 7.2292</td><td>Third  </td><td>True   </td><td>male  </td><td>Cherbourg    </td><td>dead      </td></tr>\n<tr><td style=\"text-align: right;\">   25</td><td style=\"text-align: right;\">30     </td><td>Second </td><td>False  </td><td>female</td><td>Southampton  </td><td>alived    </td></tr>\n<tr><td style=\"text-align: right;\">    7</td><td style=\"text-align: right;\">29.125 </td><td>Third  </td><td>False  </td><td>male  </td><td>Queenstown   </td><td>dead      </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[622 rows x 7 columns]</pre>"},"metadata":{}}]},{"cell_type":"markdown","source":"As a results from [Section 2.2.4 (clf-tradml-vs-automl.ipynb)](https://github.com/NhanDoV/Lectures_notes-teaching-in-VN-/blob/master/h2o_AutoML/classification/clf-tradml-vs-automl.ipynb), now we will focus on the GBM model","metadata":{}},{"cell_type":"code","source":"from h2o.estimators.gbm import H2OGradientBoostingEstimator\n\nmy_model = H2OGradientBoostingEstimator(ntrees=100, stopping_metric='auc',\n                                        keep_cross_validation_predictions = True,\n                                        stopping_rounds = 3,\n                                        model_id = \"first_model\", seed = 1234,\n                                        stopping_tolerance = 0.0005)\nmy_model.train(x = [\"class\",\"alone\",\"age\",\"fare\",\"sex\",\"embark_town\"], y = \"survived\", \n               training_frame = h2o_train_df, \n               validation_frame = h2o_valid_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:28.956137Z","iopub.execute_input":"2024-03-04T05:09:28.956816Z","iopub.status.idle":"2024-03-04T05:09:30.354381Z","shell.execute_reply.started":"2024-03-04T05:09:28.956770Z","shell.execute_reply":"2024-03-04T05:09:30.346054Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: first_model\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    6                  6                           1704                   5            5            5             16            19            18\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.15356659856582391\nRMSE: 0.3918757437834395\nLogLoss: 0.48849047101030363\nMean Per-Class Error: 0.1797312675070028\nAUC: 0.8997833508403361\nAUCPR: 0.9248738133267748\nGini: 0.7995667016806722\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.5962821147344921\n        alived    dead    Error    Rate\n------  --------  ------  -------  -------------\nalived  176       62      0.2605   (62.0/238.0)\ndead    38        346     0.099    (38.0/384.0)\nTotal   214       408     0.1608   (100.0/622.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.596282     0.873737  28\nmax f2                       0.437787     0.934602  44\nmax f0point5                 0.641435     0.870879  22\nmax accuracy                 0.605223     0.840836  27\nmax precision                0.759321     1         0\nmax recall                   0.353874     1         47\nmax specificity              0.759321     1         0\nmax absolute_mcc             0.605223     0.661856  27\nmax min_per_class_accuracy   0.641435     0.823529  22\nmax mean_per_class_accuracy  0.605223     0.829558  27\nmax tns                      0.759321     238       0\nmax fns                      0.759321     373       0\nmax fps                      0.328924     238       50\nmax tps                      0.353874     384       47\nmax tnr                      0.759321     1         0\nmax fnr                      0.759321     0.971354  0\nmax fpr                      0.328924     1         50\nmax tpr                      0.353874     1         47\n\nGains/Lift Table: Avg response rate: 61.74 %, avg score: 61.65 %\ngroup    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  ---------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0176849                   0.759321           1.61979    1.61979            1                0.759321  1                           0.759321            0.0286458       0.0286458                  61.9792   61.9792            0.0286458\n2        0.0498392                   0.75848            1.61979    1.61979            1                0.75848   1                           0.758778            0.0520833       0.0807292                  61.9792   61.9792            0.0807292\n3        0.0675241                   0.757201           1.61979    1.61979            1                0.757201  1                           0.758365            0.0286458       0.109375                   61.9792   61.9792            0.109375\n4        0.210611                    0.74854            1.52879    1.55797            0.94382          0.749134  0.961832                    0.752094            0.21875         0.328125                   52.8792   55.7968            0.307117\n5        0.451768                    0.738067           1.40382    1.47568            0.866667         0.738284  0.911032                    0.744722            0.338542        0.666667                   40.3819   47.5682            0.561625\n6        0.506431                    0.703117           1.23866    1.4501             0.764706         0.724618  0.895238                    0.742552            0.0677083       0.734375                   23.8664   45.0099            0.59572\n7        0.614148                    0.60566            1.2088     1.40778            0.746269         0.655206  0.86911                     0.727232            0.130208        0.864583                   20.88     40.7777            0.654499\n8        0.699357                    0.532466           0.733491   1.32562            0.45283          0.583749  0.818391                    0.70975             0.0625          0.927083                   -26.6509  32.5623            0.595151\n9        0.824759                    0.437787           0.560697   1.20932            0.346154         0.480059  0.746589                    0.674826            0.0703125       0.997396                   -43.9303  20.9318            0.451177\n10       0.900322                    0.339642           0.0344637  1.11071            0.0212766        0.358975  0.685714                    0.648318            0.00260417      1                          -96.5536  11.0714            0.260504\n11       1                           0.328924           0          1                  0                0.328924  0.617363                    0.616481            0               1                          -100      0                  0\n\nModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.15958625402443408\nRMSE: 0.3994824827504131\nLogLoss: 0.501297774967354\nMean Per-Class Error: 0.22032085561497325\nAUC: 0.8516636957813429\nAUCPR: 0.8432878370895138\nGini: 0.7033273915626859\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.49855256620415683\n        alived    dead    Error    Rate\n------  --------  ------  -------  ------------\nalived  62        40      0.3922   (40.0/102.0)\ndead    8         157     0.0485   (8.0/165.0)\nTotal   70        197     0.1798   (48.0/267.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.498553     0.867403  29\nmax f2                       0.481864     0.916955  32\nmax f0point5                 0.729986     0.865801  7\nmax accuracy                 0.498553     0.820225  29\nmax precision                0.729986     0.909091  7\nmax recall                   0.328924     1         39\nmax specificity              0.759321     0.980392  0\nmax absolute_mcc             0.498553     0.617945  29\nmax min_per_class_accuracy   0.681724     0.787879  14\nmax mean_per_class_accuracy  0.683245     0.812478  13\nmax tns                      0.759321     100       0\nmax fns                      0.759321     160       0\nmax fps                      0.328924     102       39\nmax tps                      0.328924     165       39\nmax tnr                      0.759321     0.980392  0\nmax fnr                      0.759321     0.969697  0\nmax fpr                      0.328924     1         39\nmax tpr                      0.328924     1         39\n\nGains/Lift Table: Avg response rate: 61.80 %, avg score: 61.53 %\ngroup    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0262172                   0.759321           1.15584   1.15584            0.714286         0.759321  0.714286                    0.759321            0.030303        0.030303                   15.5844   15.5844            0.0106952\n2        0.0599251                   0.75848            1.43838   1.31477            0.888889         0.75848   0.8125                      0.758848            0.0484848       0.0787879                  43.8384   31.4773            0.0493761\n3        0.11236                     0.752947           1.27143   1.29455            0.785714         0.75477   0.8                         0.756945            0.0666667       0.145455                   27.1429   29.4545            0.086631\n4        0.224719                    0.74854            1.45636   1.37545            0.9              0.74854   0.85                        0.752742            0.163636        0.309091                   45.6364   37.5455            0.220856\n5        0.490637                    0.738067           1.54981   1.46995            0.957746         0.738412  0.908397                    0.744976            0.412121        0.721212                   54.9808   46.9951            0.603565\n6        0.505618                    0.725916           0.809091  1.45037            0.5              0.726933  0.896296                    0.744441            0.0121212       0.733333                   -19.0909  45.037             0.596078\n7        0.621723                    0.60566            0.939589  1.35498            0.580645         0.654814  0.837349                    0.727704            0.109091        0.842424                   -6.04106  35.4984            0.577718\n8        0.70412                     0.535462           0.882645  1.29971            0.545455         0.577271  0.803191                    0.7101              0.0727273       0.915152                   -11.7355  29.971             0.552406\n9        0.797753                    0.435958           0.517818  1.20794            0.32             0.488784  0.746479                    0.684124            0.0484848       0.963636                   -48.2182  20.7939            0.434225\n10       1                           0.328924           0.179798  1                  0.111111         0.343701  0.617978                    0.615274            0.0363636       1                          -82.0202  0                  0\n\nScoring History: \n    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n    2024-03-04 05:09:29  0.118 sec   0                  0.486031         0.66534             0.5             0.617363           1                0.382637                         0.485882           0.665046              0.5               0.617978             1                  0.382022\n    2024-03-04 05:09:29  0.579 sec   1                  0.462673         0.618892            0.878748        0.886482           1.50409          0.167203                         0.463574           0.620633              0.859893          0.860926             1.21364            0.191011\n    2024-03-04 05:09:29  0.693 sec   2                  0.443059         0.581832            0.884328        0.905148           1.61979          0.167203                         0.445385           0.586142              0.852704          0.849852             1.31477            0.191011\n    2024-03-04 05:09:29  0.791 sec   3                  0.426604         0.551629            0.887884        0.91004            1.61979          0.167203                         0.430969           0.559455              0.848277          0.85045              1.43838            0.191011\n    2024-03-04 05:09:29  0.876 sec   4                  0.413147         0.527244            0.892573        0.916658           1.61979          0.167203                         0.418509           0.536601              0.847891          0.848664             1.43838            0.179775\n    2024-03-04 05:09:30  0.965 sec   5                  0.401852         0.506744            0.89603         0.920484           1.61979          0.173633                         0.407962           0.517106              0.852525          0.853194             1.43838            0.179775\n    2024-03-04 05:09:30  1.022 sec   6                  0.391876         0.48849             0.899783        0.924874           1.61979          0.160772                         0.399482           0.501298              0.851664          0.843288             1.15584            0.179775\n\nVariable Importances: \nvariable     relative_importance    scaled_importance    percentage\n-----------  ---------------------  -------------------  ------------\nsex          164.676                1                    0.605657\nclass        55.4727                0.33686              0.204022\nage          23.608                 0.14336              0.0868271\nfare         20.3601                0.123638             0.074882\nembark_town  6.68062                0.0405683            0.0245705\nalone        1.09898                0.00667358           0.0040419\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: first_model\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-2.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-2 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-2 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-2 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-2 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-2 .h2o-table th,\n#h2o-table-2 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-2 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-2\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th>\n<th>number_of_internal_trees</th>\n<th>model_size_in_bytes</th>\n<th>min_depth</th>\n<th>max_depth</th>\n<th>mean_depth</th>\n<th>min_leaves</th>\n<th>max_leaves</th>\n<th>mean_leaves</th></tr></thead>\n    <tbody><tr><td></td>\n<td>6.0</td>\n<td>6.0</td>\n<td>1704.0</td>\n<td>5.0</td>\n<td>5.0</td>\n<td>5.0</td>\n<td>16.0</td>\n<td>19.0</td>\n<td>18.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.15356659856582391\nRMSE: 0.3918757437834395\nLogLoss: 0.48849047101030363\nMean Per-Class Error: 0.1797312675070028\nAUC: 0.8997833508403361\nAUCPR: 0.9248738133267748\nGini: 0.7995667016806722</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-3.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-3 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-3 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-3 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-3 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-3 .h2o-table th,\n#h2o-table-3 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-3 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-3\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5962821147344921</caption>\n    <thead><tr><th></th>\n<th>alived</th>\n<th>dead</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>alived</td>\n<td>176.0</td>\n<td>62.0</td>\n<td>0.2605</td>\n<td> (62.0/238.0)</td></tr>\n<tr><td>dead</td>\n<td>38.0</td>\n<td>346.0</td>\n<td>0.099</td>\n<td> (38.0/384.0)</td></tr>\n<tr><td>Total</td>\n<td>214.0</td>\n<td>408.0</td>\n<td>0.1608</td>\n<td> (100.0/622.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-4.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-4 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-4 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-4 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-4 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-4 .h2o-table th,\n#h2o-table-4 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-4 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-4\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.5962821</td>\n<td>0.8737374</td>\n<td>28.0</td></tr>\n<tr><td>max f2</td>\n<td>0.4377871</td>\n<td>0.9346022</td>\n<td>44.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.6414353</td>\n<td>0.8708791</td>\n<td>22.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.6052235</td>\n<td>0.8408360</td>\n<td>27.0</td></tr>\n<tr><td>max precision</td>\n<td>0.7593211</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.3538742</td>\n<td>1.0</td>\n<td>47.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.7593211</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.6052235</td>\n<td>0.6618563</td>\n<td>27.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.6414353</td>\n<td>0.8235294</td>\n<td>22.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.6052235</td>\n<td>0.8295584</td>\n<td>27.0</td></tr>\n<tr><td>max tns</td>\n<td>0.7593211</td>\n<td>238.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.7593211</td>\n<td>373.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.3289240</td>\n<td>238.0</td>\n<td>50.0</td></tr>\n<tr><td>max tps</td>\n<td>0.3538742</td>\n<td>384.0</td>\n<td>47.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.7593211</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.7593211</td>\n<td>0.9713542</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.3289240</td>\n<td>1.0</td>\n<td>50.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.3538742</td>\n<td>1.0</td>\n<td>47.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-5.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-5 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-5 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-5 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-5 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-5 .h2o-table th,\n#h2o-table-5 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-5 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-5\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 61.74 %, avg score: 61.65 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0176849</td>\n<td>0.7593211</td>\n<td>1.6197917</td>\n<td>1.6197917</td>\n<td>1.0</td>\n<td>0.7593211</td>\n<td>1.0</td>\n<td>0.7593211</td>\n<td>0.0286458</td>\n<td>0.0286458</td>\n<td>61.9791667</td>\n<td>61.9791667</td>\n<td>0.0286458</td></tr>\n<tr><td>2</td>\n<td>0.0498392</td>\n<td>0.7584800</td>\n<td>1.6197917</td>\n<td>1.6197917</td>\n<td>1.0</td>\n<td>0.7584800</td>\n<td>1.0</td>\n<td>0.7587785</td>\n<td>0.0520833</td>\n<td>0.0807292</td>\n<td>61.9791667</td>\n<td>61.9791667</td>\n<td>0.0807292</td></tr>\n<tr><td>3</td>\n<td>0.0675241</td>\n<td>0.7572008</td>\n<td>1.6197917</td>\n<td>1.6197917</td>\n<td>1.0</td>\n<td>0.7572008</td>\n<td>1.0</td>\n<td>0.7583653</td>\n<td>0.0286458</td>\n<td>0.109375</td>\n<td>61.9791667</td>\n<td>61.9791667</td>\n<td>0.109375</td></tr>\n<tr><td>4</td>\n<td>0.2106109</td>\n<td>0.7485399</td>\n<td>1.5287921</td>\n<td>1.5579676</td>\n<td>0.9438202</td>\n<td>0.7491341</td>\n<td>0.9618321</td>\n<td>0.7520937</td>\n<td>0.21875</td>\n<td>0.328125</td>\n<td>52.8792135</td>\n<td>55.7967557</td>\n<td>0.3071166</td></tr>\n<tr><td>5</td>\n<td>0.4517685</td>\n<td>0.7380668</td>\n<td>1.4038194</td>\n<td>1.4756821</td>\n<td>0.8666667</td>\n<td>0.7382839</td>\n<td>0.9110320</td>\n<td>0.7447219</td>\n<td>0.3385417</td>\n<td>0.6666667</td>\n<td>40.3819444</td>\n<td>47.5682088</td>\n<td>0.5616246</td></tr>\n<tr><td>6</td>\n<td>0.5064309</td>\n<td>0.7031170</td>\n<td>1.2386642</td>\n<td>1.4500992</td>\n<td>0.7647059</td>\n<td>0.7246177</td>\n<td>0.8952381</td>\n<td>0.7425520</td>\n<td>0.0677083</td>\n<td>0.734375</td>\n<td>23.8664216</td>\n<td>45.0099206</td>\n<td>0.5957195</td></tr>\n<tr><td>7</td>\n<td>0.6141479</td>\n<td>0.6056603</td>\n<td>1.2087998</td>\n<td>1.4077771</td>\n<td>0.7462687</td>\n<td>0.6552063</td>\n<td>0.8691099</td>\n<td>0.7272322</td>\n<td>0.1302083</td>\n<td>0.8645833</td>\n<td>20.8799751</td>\n<td>40.7777051</td>\n<td>0.6544993</td></tr>\n<tr><td>8</td>\n<td>0.6993569</td>\n<td>0.5324663</td>\n<td>0.7334906</td>\n<td>1.3256226</td>\n<td>0.4528302</td>\n<td>0.5837490</td>\n<td>0.8183908</td>\n<td>0.7097503</td>\n<td>0.0625</td>\n<td>0.9270833</td>\n<td>-26.6509434</td>\n<td>32.5622605</td>\n<td>0.5951506</td></tr>\n<tr><td>9</td>\n<td>0.8247588</td>\n<td>0.4377871</td>\n<td>0.5606971</td>\n<td>1.2093181</td>\n<td>0.3461538</td>\n<td>0.4800586</td>\n<td>0.7465887</td>\n<td>0.6748264</td>\n<td>0.0703125</td>\n<td>0.9973958</td>\n<td>-43.9302885</td>\n<td>20.9318145</td>\n<td>0.4511773</td></tr>\n<tr><td>10</td>\n<td>0.9003215</td>\n<td>0.3396420</td>\n<td>0.0344637</td>\n<td>1.1107143</td>\n<td>0.0212766</td>\n<td>0.3589755</td>\n<td>0.6857143</td>\n<td>0.6483175</td>\n<td>0.0026042</td>\n<td>1.0</td>\n<td>-96.5536348</td>\n<td>11.0714286</td>\n<td>0.2605042</td></tr>\n<tr><td>11</td>\n<td>1.0</td>\n<td>0.3289240</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.3289240</td>\n<td>0.6173633</td>\n<td>0.6164809</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.15958625402443408\nRMSE: 0.3994824827504131\nLogLoss: 0.501297774967354\nMean Per-Class Error: 0.22032085561497325\nAUC: 0.8516636957813429\nAUCPR: 0.8432878370895138\nGini: 0.7033273915626859</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-6.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-6 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-6 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-6 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-6 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-6 .h2o-table th,\n#h2o-table-6 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-6 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-6\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.49855256620415683</caption>\n    <thead><tr><th></th>\n<th>alived</th>\n<th>dead</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>alived</td>\n<td>62.0</td>\n<td>40.0</td>\n<td>0.3922</td>\n<td> (40.0/102.0)</td></tr>\n<tr><td>dead</td>\n<td>8.0</td>\n<td>157.0</td>\n<td>0.0485</td>\n<td> (8.0/165.0)</td></tr>\n<tr><td>Total</td>\n<td>70.0</td>\n<td>197.0</td>\n<td>0.1798</td>\n<td> (48.0/267.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-7.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-7 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-7 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-7 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-7 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-7 .h2o-table th,\n#h2o-table-7 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-7 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-7\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.4985526</td>\n<td>0.8674033</td>\n<td>29.0</td></tr>\n<tr><td>max f2</td>\n<td>0.4818640</td>\n<td>0.9169550</td>\n<td>32.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.7299864</td>\n<td>0.8658009</td>\n<td>7.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.4985526</td>\n<td>0.8202247</td>\n<td>29.0</td></tr>\n<tr><td>max precision</td>\n<td>0.7299864</td>\n<td>0.9090909</td>\n<td>7.0</td></tr>\n<tr><td>max recall</td>\n<td>0.3289240</td>\n<td>1.0</td>\n<td>39.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.7593211</td>\n<td>0.9803922</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.4985526</td>\n<td>0.6179453</td>\n<td>29.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.6817240</td>\n<td>0.7878788</td>\n<td>14.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.6832448</td>\n<td>0.8124777</td>\n<td>13.0</td></tr>\n<tr><td>max tns</td>\n<td>0.7593211</td>\n<td>100.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.7593211</td>\n<td>160.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.3289240</td>\n<td>102.0</td>\n<td>39.0</td></tr>\n<tr><td>max tps</td>\n<td>0.3289240</td>\n<td>165.0</td>\n<td>39.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.7593211</td>\n<td>0.9803922</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.7593211</td>\n<td>0.9696970</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.3289240</td>\n<td>1.0</td>\n<td>39.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.3289240</td>\n<td>1.0</td>\n<td>39.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-8.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-8 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-8 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-8 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-8 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-8 .h2o-table th,\n#h2o-table-8 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-8 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-8\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 61.80 %, avg score: 61.53 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0262172</td>\n<td>0.7593211</td>\n<td>1.1558442</td>\n<td>1.1558442</td>\n<td>0.7142857</td>\n<td>0.7593211</td>\n<td>0.7142857</td>\n<td>0.7593211</td>\n<td>0.0303030</td>\n<td>0.0303030</td>\n<td>15.5844156</td>\n<td>15.5844156</td>\n<td>0.0106952</td></tr>\n<tr><td>2</td>\n<td>0.0599251</td>\n<td>0.7584800</td>\n<td>1.4383838</td>\n<td>1.3147727</td>\n<td>0.8888889</td>\n<td>0.7584800</td>\n<td>0.8125</td>\n<td>0.7588480</td>\n<td>0.0484848</td>\n<td>0.0787879</td>\n<td>43.8383838</td>\n<td>31.4772727</td>\n<td>0.0493761</td></tr>\n<tr><td>3</td>\n<td>0.1123596</td>\n<td>0.7529467</td>\n<td>1.2714286</td>\n<td>1.2945455</td>\n<td>0.7857143</td>\n<td>0.7547699</td>\n<td>0.8</td>\n<td>0.7569449</td>\n<td>0.0666667</td>\n<td>0.1454545</td>\n<td>27.1428571</td>\n<td>29.4545455</td>\n<td>0.0866310</td></tr>\n<tr><td>4</td>\n<td>0.2247191</td>\n<td>0.7485399</td>\n<td>1.4563636</td>\n<td>1.3754545</td>\n<td>0.9</td>\n<td>0.7485399</td>\n<td>0.85</td>\n<td>0.7527424</td>\n<td>0.1636364</td>\n<td>0.3090909</td>\n<td>45.6363636</td>\n<td>37.5454545</td>\n<td>0.2208556</td></tr>\n<tr><td>5</td>\n<td>0.4906367</td>\n<td>0.7380668</td>\n<td>1.5498079</td>\n<td>1.4699514</td>\n<td>0.9577465</td>\n<td>0.7384124</td>\n<td>0.9083969</td>\n<td>0.7449757</td>\n<td>0.4121212</td>\n<td>0.7212121</td>\n<td>54.9807939</td>\n<td>46.9951423</td>\n<td>0.6035651</td></tr>\n<tr><td>6</td>\n<td>0.5056180</td>\n<td>0.7259158</td>\n<td>0.8090909</td>\n<td>1.4503704</td>\n<td>0.5</td>\n<td>0.7269335</td>\n<td>0.8962963</td>\n<td>0.7444412</td>\n<td>0.0121212</td>\n<td>0.7333333</td>\n<td>-19.0909091</td>\n<td>45.0370370</td>\n<td>0.5960784</td></tr>\n<tr><td>7</td>\n<td>0.6217228</td>\n<td>0.6056603</td>\n<td>0.9395894</td>\n<td>1.3549836</td>\n<td>0.5806452</td>\n<td>0.6548140</td>\n<td>0.8373494</td>\n<td>0.7277036</td>\n<td>0.1090909</td>\n<td>0.8424242</td>\n<td>-6.0410557</td>\n<td>35.4983571</td>\n<td>0.5777184</td></tr>\n<tr><td>8</td>\n<td>0.7041199</td>\n<td>0.5354621</td>\n<td>0.8826446</td>\n<td>1.2997099</td>\n<td>0.5454545</td>\n<td>0.5772707</td>\n<td>0.8031915</td>\n<td>0.7100997</td>\n<td>0.0727273</td>\n<td>0.9151515</td>\n<td>-11.7355372</td>\n<td>29.9709865</td>\n<td>0.5524064</td></tr>\n<tr><td>9</td>\n<td>0.7977528</td>\n<td>0.4359577</td>\n<td>0.5178182</td>\n<td>1.2079385</td>\n<td>0.32</td>\n<td>0.4887835</td>\n<td>0.7464789</td>\n<td>0.6841236</td>\n<td>0.0484848</td>\n<td>0.9636364</td>\n<td>-48.2181818</td>\n<td>20.7938540</td>\n<td>0.4342246</td></tr>\n<tr><td>10</td>\n<td>1.0</td>\n<td>0.3289240</td>\n<td>0.1797980</td>\n<td>1.0</td>\n<td>0.1111111</td>\n<td>0.3437013</td>\n<td>0.6179775</td>\n<td>0.6152742</td>\n<td>0.0363636</td>\n<td>1.0</td>\n<td>-82.0202020</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-9.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-9 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-9 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-9 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-9 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-9 .h2o-table th,\n#h2o-table-9 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-9 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-9\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th>\n<th>validation_rmse</th>\n<th>validation_logloss</th>\n<th>validation_auc</th>\n<th>validation_pr_auc</th>\n<th>validation_lift</th>\n<th>validation_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2024-03-04 05:09:29</td>\n<td> 0.118 sec</td>\n<td>0.0</td>\n<td>0.4860307</td>\n<td>0.6653402</td>\n<td>0.5</td>\n<td>0.6173633</td>\n<td>1.0</td>\n<td>0.3826367</td>\n<td>0.4858824</td>\n<td>0.6650463</td>\n<td>0.5</td>\n<td>0.6179775</td>\n<td>1.0</td>\n<td>0.3820225</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:29</td>\n<td> 0.579 sec</td>\n<td>1.0</td>\n<td>0.4626731</td>\n<td>0.6188916</td>\n<td>0.8787476</td>\n<td>0.8864817</td>\n<td>1.5040923</td>\n<td>0.1672026</td>\n<td>0.4635740</td>\n<td>0.6206331</td>\n<td>0.8598930</td>\n<td>0.8609257</td>\n<td>1.2136364</td>\n<td>0.1910112</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:29</td>\n<td> 0.693 sec</td>\n<td>2.0</td>\n<td>0.4430590</td>\n<td>0.5818319</td>\n<td>0.8843279</td>\n<td>0.9051476</td>\n<td>1.6197917</td>\n<td>0.1672026</td>\n<td>0.4453847</td>\n<td>0.5861418</td>\n<td>0.8527035</td>\n<td>0.8498517</td>\n<td>1.3147727</td>\n<td>0.1910112</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:29</td>\n<td> 0.791 sec</td>\n<td>3.0</td>\n<td>0.4266041</td>\n<td>0.5516290</td>\n<td>0.8878841</td>\n<td>0.9100405</td>\n<td>1.6197917</td>\n<td>0.1672026</td>\n<td>0.4309694</td>\n<td>0.5594554</td>\n<td>0.8482769</td>\n<td>0.8504499</td>\n<td>1.4383838</td>\n<td>0.1910112</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:29</td>\n<td> 0.876 sec</td>\n<td>4.0</td>\n<td>0.4131466</td>\n<td>0.5272436</td>\n<td>0.8925727</td>\n<td>0.9166584</td>\n<td>1.6197917</td>\n<td>0.1672026</td>\n<td>0.4185094</td>\n<td>0.5366015</td>\n<td>0.8478907</td>\n<td>0.8486635</td>\n<td>1.4383838</td>\n<td>0.1797753</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:30</td>\n<td> 0.965 sec</td>\n<td>5.0</td>\n<td>0.4018519</td>\n<td>0.5067443</td>\n<td>0.8960303</td>\n<td>0.9204838</td>\n<td>1.6197917</td>\n<td>0.1736334</td>\n<td>0.4079617</td>\n<td>0.5171055</td>\n<td>0.8525253</td>\n<td>0.8531941</td>\n<td>1.4383838</td>\n<td>0.1797753</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:30</td>\n<td> 1.022 sec</td>\n<td>6.0</td>\n<td>0.3918757</td>\n<td>0.4884905</td>\n<td>0.8997834</td>\n<td>0.9248738</td>\n<td>1.6197917</td>\n<td>0.1607717</td>\n<td>0.3994825</td>\n<td>0.5012978</td>\n<td>0.8516637</td>\n<td>0.8432878</td>\n<td>1.1558442</td>\n<td>0.1797753</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-10.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-10 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-10 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-10 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-10 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-10 .h2o-table th,\n#h2o-table-10 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-10 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-10\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>sex</td>\n<td>164.6757507</td>\n<td>1.0</td>\n<td>0.6056568</td></tr>\n<tr><td>class</td>\n<td>55.4726906</td>\n<td>0.3368601</td>\n<td>0.2040216</td></tr>\n<tr><td>age</td>\n<td>23.6079540</td>\n<td>0.1433602</td>\n<td>0.0868271</td></tr>\n<tr><td>fare</td>\n<td>20.3601379</td>\n<td>0.1236377</td>\n<td>0.0748820</td></tr>\n<tr><td>embark_town</td>\n<td>6.6806231</td>\n<td>0.0405683</td>\n<td>0.0245705</td></tr>\n<tr><td>alone</td>\n<td>1.0989764</td>\n<td>0.0066736</td>\n<td>0.0040419</td></tr></tbody>\n  </table>\n</div>\n</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]},{"cell_type":"code","source":"my_model.model_id","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:30.356528Z","iopub.execute_input":"2024-03-04T05:09:30.357423Z","iopub.status.idle":"2024-03-04T05:09:30.365126Z","shell.execute_reply.started":"2024-03-04T05:09:30.357378Z","shell.execute_reply":"2024-03-04T05:09:30.364013Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'first_model'"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2. What happend if we didnt use train_test_split from `sklearn`?","metadata":{}},{"cell_type":"code","source":"# split into train and validation sets\ntrain, valid = h2o.H2OFrame(df.drop(columns=[\"alive\", \"pclass\", \"age_group\", \"faregroup\", \n                                             \"parch\", \"who\", \"sibsp\", \"adult_male\", \n                                             \"deck\", \"embarked\"])).split_frame(ratios = [.7], \n                                                                               seed = 1234)\ntrain","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:30.366782Z","iopub.execute_input":"2024-03-04T05:09:30.367463Z","iopub.status.idle":"2024-03-04T05:09:30.953264Z","shell.execute_reply.started":"2024-03-04T05:09:30.367424Z","shell.execute_reply":"2024-03-04T05:09:30.952032Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"survived    sex       age     fare  class    embark_town    alone\n----------  ------  -----  -------  -------  -------------  -------\nalived      female     38  71.2833  First    Cherbourg      False\nalived      female     26   7.925   Third    Southampton    True\ndead        male       35   8.05    Third    Southampton    True\ndead        male       28   8.4583  Third    Queenstown     True\ndead        male       54  51.8625  First    Southampton    True\ndead        male        2  21.075   Third    Southampton    False\nalived      female     27  11.1333  Third    Southampton    False\nalived      female      4  16.7     Third    Southampton    False\nalived      female     58  26.55    First    Southampton    True\ndead        male       20   8.05    Third    Southampton    True\n[634 rows x 7 columns]\n","text/html":"<table class='dataframe'>\n<thead>\n<tr><th>survived  </th><th>sex   </th><th style=\"text-align: right;\">  age</th><th style=\"text-align: right;\">   fare</th><th>class  </th><th>embark_town  </th><th>alone  </th></tr>\n</thead>\n<tbody>\n<tr><td>alived    </td><td>female</td><td style=\"text-align: right;\">   38</td><td style=\"text-align: right;\">71.2833</td><td>First  </td><td>Cherbourg    </td><td>False  </td></tr>\n<tr><td>alived    </td><td>female</td><td style=\"text-align: right;\">   26</td><td style=\"text-align: right;\"> 7.925 </td><td>Third  </td><td>Southampton  </td><td>True   </td></tr>\n<tr><td>dead      </td><td>male  </td><td style=\"text-align: right;\">   35</td><td style=\"text-align: right;\"> 8.05  </td><td>Third  </td><td>Southampton  </td><td>True   </td></tr>\n<tr><td>dead      </td><td>male  </td><td style=\"text-align: right;\">   28</td><td style=\"text-align: right;\"> 8.4583</td><td>Third  </td><td>Queenstown   </td><td>True   </td></tr>\n<tr><td>dead      </td><td>male  </td><td style=\"text-align: right;\">   54</td><td style=\"text-align: right;\">51.8625</td><td>First  </td><td>Southampton  </td><td>True   </td></tr>\n<tr><td>dead      </td><td>male  </td><td style=\"text-align: right;\">    2</td><td style=\"text-align: right;\">21.075 </td><td>Third  </td><td>Southampton  </td><td>False  </td></tr>\n<tr><td>alived    </td><td>female</td><td style=\"text-align: right;\">   27</td><td style=\"text-align: right;\">11.1333</td><td>Third  </td><td>Southampton  </td><td>False  </td></tr>\n<tr><td>alived    </td><td>female</td><td style=\"text-align: right;\">    4</td><td style=\"text-align: right;\">16.7   </td><td>Third  </td><td>Southampton  </td><td>False  </td></tr>\n<tr><td>alived    </td><td>female</td><td style=\"text-align: right;\">   58</td><td style=\"text-align: right;\">26.55  </td><td>First  </td><td>Southampton  </td><td>True   </td></tr>\n<tr><td>dead      </td><td>male  </td><td style=\"text-align: right;\">   20</td><td style=\"text-align: right;\"> 8.05  </td><td>Third  </td><td>Southampton  </td><td>True   </td></tr>\n</tbody>\n</table><pre style='font-size: smaller; margin-bottom: 1em;'>[634 rows x 7 columns]</pre>"},"metadata":{}}]},{"cell_type":"code","source":"my_model = H2OGradientBoostingEstimator(ntrees=100, stopping_metric='auc',\n                                        keep_cross_validation_predictions = True,\n                                        stopping_rounds = 3,\n                                        model_id = \"first_model\", seed = 1234,\n                                        stopping_tolerance = 0.0005)\nmy_model.train(x = [\"class\",\"alone\",\"age\",\"fare\",\"sex\",\"embark_town\"], y = \"survived\", \n               training_frame = train, \n               validation_frame = valid)","metadata":{"execution":{"iopub.status.busy":"2024-03-04T05:09:30.956586Z","iopub.execute_input":"2024-03-04T05:09:30.957665Z","iopub.status.idle":"2024-03-04T05:09:31.784596Z","shell.execute_reply.started":"2024-03-04T05:09:30.957621Z","shell.execute_reply":"2024-03-04T05:09:31.783666Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: first_model\n\n\nModel Summary: \n    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n    15                 15                          4382                   5            5            5             17            22            18.6\n\nModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.1170673001067649\nRMSE: 0.3421509902174256\nLogLoss: 0.3938495857075096\nMean Per-Class Error: 0.1677128121436567\nAUC: 0.9156179058259841\nAUCPR: 0.9343343321265223\nGini: 0.8312358116519682\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.46858711430793226\n        alived    dead    Error    Rate\n------  --------  ------  -------  ------------\nalived  175       72      0.2915   (72.0/247.0)\ndead    17        370     0.0439   (17.0/387.0)\nTotal   192       442     0.1404   (89.0/634.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.468587     0.892642  132\nmax f2                       0.297915     0.93046   159\nmax f0point5                 0.624654     0.893326  96\nmax accuracy                 0.624654     0.864353  96\nmax precision                0.888371     1         0\nmax recall                   0.221493     1         176\nmax specificity              0.888371     1         0\nmax absolute_mcc             0.624654     0.71671   96\nmax min_per_class_accuracy   0.67317      0.850202  88\nmax mean_per_class_accuracy  0.624654     0.860329  96\nmax tns                      0.888371     247       0\nmax fns                      0.888371     386       0\nmax fps                      0.127531     247       204\nmax tps                      0.221493     387       176\nmax tnr                      0.888371     1         0\nmax fnr                      0.888371     0.997416  0\nmax fpr                      0.127531     1         204\nmax tpr                      0.221493     1         176\n\nGains/Lift Table: Avg response rate: 61.04 %, avg score: 61.00 %\ngroup    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.011041                    0.867744           1.63824   1.63824            1                0.877986  1                           0.877986            0.0180879       0.0180879                  63.8243   63.8243            0.0180879\n2        0.0283912                   0.855503           1.63824   1.63824            1                0.857872  1                           0.865694            0.0284238       0.0465116                  63.8243   63.8243            0.0465116\n3        0.0299685                   0.853691           1.63824   1.63824            1                0.855029  1                           0.865133            0.00258398      0.0490956                  63.8243   63.8243            0.0490956\n4        0.0410095                   0.847898           1.63824   1.63824            1                0.852321  1                           0.861684            0.0180879       0.0671835                  63.8243   63.8243            0.0671835\n5        0.0536278                   0.842462           1.63824   1.63824            1                0.844637  1                           0.857673            0.0206718       0.0878553                  63.8243   63.8243            0.0878553\n6        0.108833                    0.836276           1.59144   1.6145             0.971429         0.838481  0.985507                    0.847938            0.0878553       0.175711                   59.1436   61.45              0.171662\n7        0.200315                    0.830856           1.55351   1.58664            0.948276         0.830964  0.968504                    0.840186            0.142119        0.317829                   55.3506   58.6645            0.301635\n8        0.200315                    0.830201           0         1.58664            0                0         0.968504                    0.840186            0               0.317829                   -100      58.6645            0.301635\n9        0.321767                    0.827026           1.44676   1.53385            0.883117         0.827946  0.936275                    0.835566            0.175711        0.49354                    44.676    53.3845            0.440908\n10       0.411672                    0.814533           1.49454   1.52526            0.912281         0.818366  0.931034                    0.83181             0.134367        0.627907                   49.4537   52.5261            0.555032\n11       0.503155                    0.776319           1.27105   1.47904            0.775862         0.793156  0.902821                    0.824782            0.116279        0.744186                   27.1051   47.9041            0.61868\n12       0.600946                    0.623245           1.37401   1.46195            0.83871          0.699343  0.892388                    0.804369            0.134367        0.878553                   37.401    46.1949            0.712561\n13       0.700315                    0.463242           0.780116  1.3652             0.47619          0.546656  0.833333                    0.767802            0.0775194       0.956072                   -21.9884  36.5202            0.656477\n14       0.799685                    0.270397           0.312046  1.23434            0.190476         0.359974  0.753452                    0.717125            0.0310078       0.98708                    -68.7954  23.4337            0.481007\n15       0.900631                    0.177704           0.127988  1.11033            0.078125         0.216955  0.677758                    0.661064            0.0129199       1                          -87.2012  11.0333            0.255061\n16       1                           0.127531           0         1                  0                0.147576  0.61041                     0.610039            0               1                          -100      0                  0\n\nModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.13024698625212555\nRMSE: 0.3608974733246626\nLogLoss: 0.42350377899215336\nMean Per-Class Error: 0.21286340103544404\nAUC: 0.8822846143634674\nAUCPR: 0.9026780999667338\nGini: 0.7645692287269348\n\nConfusion Matrix (Act/Pred) for max f1 @ threshold = 0.4079467943979526\n        alived    dead    Error    Rate\n------  --------  ------  -------  ------------\nalived  58        35      0.3763   (35.0/93.0)\ndead    8         154     0.0494   (8.0/162.0)\nTotal   66        189     0.1686   (43.0/255.0)\n\nMaximum Metrics: Maximum metrics at their respective thresholds\nmetric                       threshold    value     idx\n---------------------------  -----------  --------  -----\nmax f1                       0.407947     0.877493  69\nmax f2                       0.257088     0.934959  85\nmax f0point5                 0.696561     0.878747  39\nmax accuracy                 0.463257     0.831373  66\nmax precision                0.855503     1         0\nmax recall                   0.171724     1         101\nmax specificity              0.855503     1         0\nmax absolute_mcc             0.650423     0.63348   48\nmax min_per_class_accuracy   0.675789     0.806452  43\nmax mean_per_class_accuracy  0.696561     0.822879  39\nmax tns                      0.855503     93        0\nmax fns                      0.855503     159       0\nmax fps                      0.127531     93        108\nmax tps                      0.171724     162       101\nmax tnr                      0.855503     1         0\nmax fnr                      0.855503     0.981481  0\nmax fpr                      0.127531     1         108\nmax tpr                      0.171724     1         101\n\nGains/Lift Table: Avg response rate: 63.53 %, avg score: 61.77 %\ngroup    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score     cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n-------  --------------------------  -----------------  --------  -----------------  ---------------  --------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n1        0.0117647                   0.854658           1.57407   1.57407            1                0.855503  1                           0.855503            0.0185185       0.0185185                  57.4074   57.4074            0.0185185\n2        0.0235294                   0.852056           1.04938   1.31173            0.666667         0.853249  0.833333                    0.854376            0.0123457       0.0308642                  4.93827   31.1728            0.0201115\n3        0.0392157                   0.847578           1.57407   1.41667            1                0.848479  0.9                         0.852017            0.0246914       0.0555556                  57.4074   41.6667            0.0448029\n4        0.0431373                   0.844895           1.57407   1.43098            1                0.846047  0.909091                    0.851475            0.00617284      0.0617284                  57.4074   43.0976            0.0509757\n5        0.0509804                   0.837181           1.57407   1.45299            1                0.838844  0.923077                    0.849532            0.0123457       0.0740741                  57.4074   45.2991            0.0633214\n6        0.172549                    0.830856           1.42174   1.43098            0.903226         0.832282  0.909091                    0.837378            0.17284         0.246914                   42.1744   43.0976            0.203903\n7        0.207843                    0.828781           1.57407   1.45528            1                0.828781  0.924528                    0.835919            0.0555556       0.302469                   57.4074   45.5276            0.259458\n8        0.313725                    0.827026           1.51578   1.47569            0.962963         0.827068  0.9375                      0.832932            0.160494        0.462963                   51.5775   47.5694            0.4092\n9        0.419608                    0.814533           1.45748   1.4711             0.925926         0.81806   0.934579                    0.829179            0.154321        0.617284                   45.7476   47.1097            0.542015\n10       0.501961                    0.734524           1.27425   1.4388             0.809524         0.786836  0.914062                    0.822232            0.104938        0.722222                   27.425    43.8802            0.603943\n11       0.607843                    0.650619           1.10768   1.38112            0.703704         0.697914  0.877419                    0.800577            0.117284        0.839506                   10.7682   38.1123            0.635205\n12       0.701961                    0.511997           0.721451  1.29268            0.458333         0.589425  0.821229                    0.772266            0.0679012       0.907407                   -27.8549  29.2675            0.563321\n13       0.8                         0.296597           0.62963   1.21142            0.4              0.384837  0.769608                    0.724787            0.0617284       0.969136                   -37.037   21.142             0.463759\n14       0.901961                    0.180827           0.242165  1.10185            0.153846         0.222695  0.7                         0.668028            0.0246914       0.993827                   -75.7835  10.1852            0.251892\n15       1                           0.127531           0.062963  1                  0.04             0.154431  0.635294                    0.617676            0.00617284      1                          -93.7037  0                  0\n\nScoring History: \n    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -------------------  -----------------  ---------------------------------\n    2024-03-04 05:09:30  0.005 sec   0                  0.487657         0.668564            0.5             0.61041            1                0.38959                          0.48199            0.65739               0.5               0.635294             1                  0.364706\n    2024-03-04 05:09:31  0.069 sec   1                  0.4648           0.62315             0.877088        0.893577           1.59624          0.173502                         0.461146           0.616341              0.862273          0.880933             1.41667            0.192157\n    2024-03-04 05:09:31  0.112 sec   2                  0.44496          0.585626            0.885515        0.904717           1.63824          0.165615                         0.443922           0.583805              0.864596          0.890552             1.57407            0.180392\n    2024-03-04 05:09:31  0.154 sec   3                  0.428881         0.556035            0.885651        0.904735           1.63824          0.165615                         0.429389           0.556971              0.865359          0.890778             1.57407            0.180392\n    2024-03-04 05:09:31  0.200 sec   4                  0.41538          0.531491            0.884364        0.90402            1.63824          0.165615                         0.417138           0.534552              0.866222          0.891374             1.57407            0.180392\n    2024-03-04 05:09:31  0.243 sec   5                  0.403229         0.509569            0.894345        0.911302           1.63824          0.165615                         0.405548           0.513537              0.871565          0.89856              1.57407            0.176471\n    2024-03-04 05:09:31  0.280 sec   6                  0.392052         0.489523            0.897881        0.915113           1.63824          0.14511                          0.397746           0.499086              0.870769          0.892819             1.57407            0.176471\n    2024-03-04 05:09:31  0.316 sec   7                  0.383534         0.473909            0.896421        0.912271           1.63824          0.141956                         0.388659           0.482327              0.88265           0.906649             1.57407            0.176471\n    2024-03-04 05:09:31  0.351 sec   8                  0.3754           0.459091            0.897833        0.914041           1.63824          0.138801                         0.384218           0.473296              0.875714          0.89594              1.57407            0.176471\n    2024-03-04 05:09:31  0.385 sec   9                  0.368014         0.44508             0.905878        0.925078           1.63824          0.138801                         0.377832           0.461021              0.876776          0.899063             1.57407            0.176471\n    2024-03-04 05:09:31  0.419 sec   10                 0.362562         0.434478            0.908264        0.926253           1.63824          0.138801                         0.37306            0.451392              0.884707          0.9074               1.57407            0.172549\n    2024-03-04 05:09:31  0.461 sec   11                 0.357213         0.424348            0.909718        0.927151           1.63824          0.138801                         0.370412           0.44535               0.883977          0.907028             1.57407            0.168627\n    2024-03-04 05:09:31  0.498 sec   12                 0.352255         0.414791            0.911554        0.928758           1.63824          0.138801                         0.367515           0.438923              0.88192           0.906341             1.57407            0.168627\n    2024-03-04 05:09:31  0.534 sec   13                 0.348539         0.407119            0.911658        0.92876            1.63824          0.137224                         0.364646           0.432727              0.883446          0.905669             1.57407            0.168627\n    2024-03-04 05:09:31  0.575 sec   14                 0.345365         0.400434            0.914415        0.933083           1.63824          0.140379                         0.361893           0.426659              0.882285          0.900897             1.57407            0.168627\n    2024-03-04 05:09:31  0.610 sec   15                 0.342151         0.39385             0.915618        0.934334           1.63824          0.140379                         0.360897           0.423504              0.882285          0.902678             1.57407            0.168627\n\nVariable Importances: \nvariable     relative_importance    scaled_importance    percentage\n-----------  ---------------------  -------------------  ------------\nsex          228.382                1                    0.559914\nfare         71.5017                0.313079             0.175297\nclass        62.4219                0.273322             0.153037\nage          39.2426                0.171828             0.096209\nembark_town  6.26377                0.0274267            0.0153566\nalone        0.0762307              0.000333785          0.000186891\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.","text/html":"<pre style='margin: 1em 0 1em 0;'>Model Details\n=============\nH2OGradientBoostingEstimator : Gradient Boosting Machine\nModel Key: first_model\n</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-11.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-11 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-11 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-11 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-11 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-11 .h2o-table th,\n#h2o-table-11 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-11 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-11\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Model Summary: </caption>\n    <thead><tr><th></th>\n<th>number_of_trees</th>\n<th>number_of_internal_trees</th>\n<th>model_size_in_bytes</th>\n<th>min_depth</th>\n<th>max_depth</th>\n<th>mean_depth</th>\n<th>min_leaves</th>\n<th>max_leaves</th>\n<th>mean_leaves</th></tr></thead>\n    <tbody><tr><td></td>\n<td>15.0</td>\n<td>15.0</td>\n<td>4382.0</td>\n<td>5.0</td>\n<td>5.0</td>\n<td>5.0</td>\n<td>17.0</td>\n<td>22.0</td>\n<td>18.6</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on train data. **\n\nMSE: 0.1170673001067649\nRMSE: 0.3421509902174256\nLogLoss: 0.3938495857075096\nMean Per-Class Error: 0.1677128121436567\nAUC: 0.9156179058259841\nAUCPR: 0.9343343321265223\nGini: 0.8312358116519682</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-12.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-12 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-12 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-12 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-12 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-12 .h2o-table th,\n#h2o-table-12 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-12 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-12\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46858711430793226</caption>\n    <thead><tr><th></th>\n<th>alived</th>\n<th>dead</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>alived</td>\n<td>175.0</td>\n<td>72.0</td>\n<td>0.2915</td>\n<td> (72.0/247.0)</td></tr>\n<tr><td>dead</td>\n<td>17.0</td>\n<td>370.0</td>\n<td>0.0439</td>\n<td> (17.0/387.0)</td></tr>\n<tr><td>Total</td>\n<td>192.0</td>\n<td>442.0</td>\n<td>0.1404</td>\n<td> (89.0/634.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-13.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-13 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-13 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-13 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-13 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-13 .h2o-table th,\n#h2o-table-13 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-13 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-13\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.4685871</td>\n<td>0.8926417</td>\n<td>132.0</td></tr>\n<tr><td>max f2</td>\n<td>0.2979146</td>\n<td>0.9304603</td>\n<td>159.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.6246537</td>\n<td>0.8933263</td>\n<td>96.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.6246537</td>\n<td>0.8643533</td>\n<td>96.0</td></tr>\n<tr><td>max precision</td>\n<td>0.8883713</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.2214928</td>\n<td>1.0</td>\n<td>176.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.8883713</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.6246537</td>\n<td>0.7167103</td>\n<td>96.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.6731696</td>\n<td>0.8502024</td>\n<td>88.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.6246537</td>\n<td>0.8603291</td>\n<td>96.0</td></tr>\n<tr><td>max tns</td>\n<td>0.8883713</td>\n<td>247.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.8883713</td>\n<td>386.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.1275312</td>\n<td>247.0</td>\n<td>204.0</td></tr>\n<tr><td>max tps</td>\n<td>0.2214928</td>\n<td>387.0</td>\n<td>176.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.8883713</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.8883713</td>\n<td>0.9974160</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.1275312</td>\n<td>1.0</td>\n<td>204.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.2214928</td>\n<td>1.0</td>\n<td>176.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-14.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-14 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-14 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-14 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-14 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-14 .h2o-table th,\n#h2o-table-14 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-14 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-14\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 61.04 %, avg score: 61.00 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0110410</td>\n<td>0.8677438</td>\n<td>1.6382429</td>\n<td>1.6382429</td>\n<td>1.0</td>\n<td>0.8779861</td>\n<td>1.0</td>\n<td>0.8779861</td>\n<td>0.0180879</td>\n<td>0.0180879</td>\n<td>63.8242894</td>\n<td>63.8242894</td>\n<td>0.0180879</td></tr>\n<tr><td>2</td>\n<td>0.0283912</td>\n<td>0.8555027</td>\n<td>1.6382429</td>\n<td>1.6382429</td>\n<td>1.0</td>\n<td>0.8578724</td>\n<td>1.0</td>\n<td>0.8656944</td>\n<td>0.0284238</td>\n<td>0.0465116</td>\n<td>63.8242894</td>\n<td>63.8242894</td>\n<td>0.0465116</td></tr>\n<tr><td>3</td>\n<td>0.0299685</td>\n<td>0.8536908</td>\n<td>1.6382429</td>\n<td>1.6382429</td>\n<td>1.0</td>\n<td>0.8550286</td>\n<td>1.0</td>\n<td>0.8651330</td>\n<td>0.0025840</td>\n<td>0.0490956</td>\n<td>63.8242894</td>\n<td>63.8242894</td>\n<td>0.0490956</td></tr>\n<tr><td>4</td>\n<td>0.0410095</td>\n<td>0.8478981</td>\n<td>1.6382429</td>\n<td>1.6382429</td>\n<td>1.0</td>\n<td>0.8523212</td>\n<td>1.0</td>\n<td>0.8616837</td>\n<td>0.0180879</td>\n<td>0.0671835</td>\n<td>63.8242894</td>\n<td>63.8242894</td>\n<td>0.0671835</td></tr>\n<tr><td>5</td>\n<td>0.0536278</td>\n<td>0.8424619</td>\n<td>1.6382429</td>\n<td>1.6382429</td>\n<td>1.0</td>\n<td>0.8446374</td>\n<td>1.0</td>\n<td>0.8576728</td>\n<td>0.0206718</td>\n<td>0.0878553</td>\n<td>63.8242894</td>\n<td>63.8242894</td>\n<td>0.0878553</td></tr>\n<tr><td>6</td>\n<td>0.1088328</td>\n<td>0.8362759</td>\n<td>1.5914360</td>\n<td>1.6145002</td>\n<td>0.9714286</td>\n<td>0.8384814</td>\n<td>0.9855072</td>\n<td>0.8479380</td>\n<td>0.0878553</td>\n<td>0.1757106</td>\n<td>59.1435954</td>\n<td>61.4500243</td>\n<td>0.1716620</td></tr>\n<tr><td>7</td>\n<td>0.2003155</td>\n<td>0.8308558</td>\n<td>1.5535062</td>\n<td>1.5866447</td>\n<td>0.9482759</td>\n<td>0.8309641</td>\n<td>0.9685039</td>\n<td>0.8401861</td>\n<td>0.1421189</td>\n<td>0.3178295</td>\n<td>55.3506193</td>\n<td>58.6644693</td>\n<td>0.3016351</td></tr>\n<tr><td>8</td>\n<td>0.2003155</td>\n<td>0.8302014</td>\n<td>0.0</td>\n<td>1.5866447</td>\n<td>0.0</td>\n<td>0.0</td>\n<td>0.9685039</td>\n<td>0.8401861</td>\n<td>0.0</td>\n<td>0.3178295</td>\n<td>-100.0</td>\n<td>58.6644693</td>\n<td>0.3016351</td></tr>\n<tr><td>9</td>\n<td>0.3217666</td>\n<td>0.8270264</td>\n<td>1.4467600</td>\n<td>1.5338451</td>\n<td>0.8831169</td>\n<td>0.8279458</td>\n<td>0.9362745</td>\n<td>0.8355660</td>\n<td>0.1757106</td>\n<td>0.4935401</td>\n<td>44.6759958</td>\n<td>53.3845063</td>\n<td>0.4409085</td></tr>\n<tr><td>10</td>\n<td>0.4116719</td>\n<td>0.8145329</td>\n<td>1.4945374</td>\n<td>1.5252606</td>\n<td>0.9122807</td>\n<td>0.8183657</td>\n<td>0.9310345</td>\n<td>0.8318096</td>\n<td>0.1343669</td>\n<td>0.6279070</td>\n<td>49.4537377</td>\n<td>52.5260626</td>\n<td>0.5550325</td></tr>\n<tr><td>11</td>\n<td>0.5031546</td>\n<td>0.7763189</td>\n<td>1.2710505</td>\n<td>1.4790406</td>\n<td>0.7758621</td>\n<td>0.7931559</td>\n<td>0.9028213</td>\n<td>0.8247817</td>\n<td>0.1162791</td>\n<td>0.7441860</td>\n<td>27.1050521</td>\n<td>47.9040607</td>\n<td>0.6186800</td></tr>\n<tr><td>12</td>\n<td>0.6009464</td>\n<td>0.6232446</td>\n<td>1.3740102</td>\n<td>1.4619490</td>\n<td>0.8387097</td>\n<td>0.6993433</td>\n<td>0.8923885</td>\n<td>0.8043692</td>\n<td>0.1343669</td>\n<td>0.8785530</td>\n<td>37.4010169</td>\n<td>46.1949039</td>\n<td>0.7125611</td></tr>\n<tr><td>13</td>\n<td>0.7003155</td>\n<td>0.4632421</td>\n<td>0.7801157</td>\n<td>1.3652024</td>\n<td>0.4761905</td>\n<td>0.5466561</td>\n<td>0.8333333</td>\n<td>0.7678018</td>\n<td>0.0775194</td>\n<td>0.9560724</td>\n<td>-21.9884336</td>\n<td>36.5202412</td>\n<td>0.6564772</td></tr>\n<tr><td>14</td>\n<td>0.7996845</td>\n<td>0.2703972</td>\n<td>0.3120463</td>\n<td>1.2343369</td>\n<td>0.1904762</td>\n<td>0.3599737</td>\n<td>0.7534517</td>\n<td>0.7171249</td>\n<td>0.0310078</td>\n<td>0.9870801</td>\n<td>-68.7953734</td>\n<td>23.4336855</td>\n<td>0.4810072</td></tr>\n<tr><td>15</td>\n<td>0.9006309</td>\n<td>0.1777038</td>\n<td>0.1279877</td>\n<td>1.1103327</td>\n<td>0.078125</td>\n<td>0.2169554</td>\n<td>0.6777583</td>\n<td>0.6610639</td>\n<td>0.0129199</td>\n<td>1.0</td>\n<td>-87.2012274</td>\n<td>11.0332750</td>\n<td>0.2550607</td></tr>\n<tr><td>16</td>\n<td>1.0</td>\n<td>0.1275312</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>0.0</td>\n<td>0.1475760</td>\n<td>0.6104101</td>\n<td>0.6100390</td>\n<td>0.0</td>\n<td>1.0</td>\n<td>-100.0</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: gbm\n** Reported on validation data. **\n\nMSE: 0.13024698625212555\nRMSE: 0.3608974733246626\nLogLoss: 0.42350377899215336\nMean Per-Class Error: 0.21286340103544404\nAUC: 0.8822846143634674\nAUCPR: 0.9026780999667338\nGini: 0.7645692287269348</pre>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-15.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-15 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-15 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-15 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-15 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-15 .h2o-table th,\n#h2o-table-15 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-15 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-15\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4079467943979526</caption>\n    <thead><tr><th></th>\n<th>alived</th>\n<th>dead</th>\n<th>Error</th>\n<th>Rate</th></tr></thead>\n    <tbody><tr><td>alived</td>\n<td>58.0</td>\n<td>35.0</td>\n<td>0.3763</td>\n<td> (35.0/93.0)</td></tr>\n<tr><td>dead</td>\n<td>8.0</td>\n<td>154.0</td>\n<td>0.0494</td>\n<td> (8.0/162.0)</td></tr>\n<tr><td>Total</td>\n<td>66.0</td>\n<td>189.0</td>\n<td>0.1686</td>\n<td> (43.0/255.0)</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-16.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-16 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-16 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-16 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-16 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-16 .h2o-table th,\n#h2o-table-16 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-16 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-16\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n    <thead><tr><th>metric</th>\n<th>threshold</th>\n<th>value</th>\n<th>idx</th></tr></thead>\n    <tbody><tr><td>max f1</td>\n<td>0.4079468</td>\n<td>0.8774929</td>\n<td>69.0</td></tr>\n<tr><td>max f2</td>\n<td>0.2570878</td>\n<td>0.9349593</td>\n<td>85.0</td></tr>\n<tr><td>max f0point5</td>\n<td>0.6965612</td>\n<td>0.8787466</td>\n<td>39.0</td></tr>\n<tr><td>max accuracy</td>\n<td>0.4632575</td>\n<td>0.8313725</td>\n<td>66.0</td></tr>\n<tr><td>max precision</td>\n<td>0.8555027</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max recall</td>\n<td>0.1717245</td>\n<td>1.0</td>\n<td>101.0</td></tr>\n<tr><td>max specificity</td>\n<td>0.8555027</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max absolute_mcc</td>\n<td>0.6504232</td>\n<td>0.6334803</td>\n<td>48.0</td></tr>\n<tr><td>max min_per_class_accuracy</td>\n<td>0.6757887</td>\n<td>0.8064516</td>\n<td>43.0</td></tr>\n<tr><td>max mean_per_class_accuracy</td>\n<td>0.6965612</td>\n<td>0.8228793</td>\n<td>39.0</td></tr>\n<tr><td>max tns</td>\n<td>0.8555027</td>\n<td>93.0</td>\n<td>0.0</td></tr>\n<tr><td>max fns</td>\n<td>0.8555027</td>\n<td>159.0</td>\n<td>0.0</td></tr>\n<tr><td>max fps</td>\n<td>0.1275312</td>\n<td>93.0</td>\n<td>108.0</td></tr>\n<tr><td>max tps</td>\n<td>0.1717245</td>\n<td>162.0</td>\n<td>101.0</td></tr>\n<tr><td>max tnr</td>\n<td>0.8555027</td>\n<td>1.0</td>\n<td>0.0</td></tr>\n<tr><td>max fnr</td>\n<td>0.8555027</td>\n<td>0.9814815</td>\n<td>0.0</td></tr>\n<tr><td>max fpr</td>\n<td>0.1275312</td>\n<td>1.0</td>\n<td>108.0</td></tr>\n<tr><td>max tpr</td>\n<td>0.1717245</td>\n<td>1.0</td>\n<td>101.0</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-17.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-17 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-17 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-17 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-17 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-17 .h2o-table th,\n#h2o-table-17 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-17 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-17\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Gains/Lift Table: Avg response rate: 63.53 %, avg score: 61.77 %</caption>\n    <thead><tr><th>group</th>\n<th>cumulative_data_fraction</th>\n<th>lower_threshold</th>\n<th>lift</th>\n<th>cumulative_lift</th>\n<th>response_rate</th>\n<th>score</th>\n<th>cumulative_response_rate</th>\n<th>cumulative_score</th>\n<th>capture_rate</th>\n<th>cumulative_capture_rate</th>\n<th>gain</th>\n<th>cumulative_gain</th>\n<th>kolmogorov_smirnov</th></tr></thead>\n    <tbody><tr><td>1</td>\n<td>0.0117647</td>\n<td>0.8546581</td>\n<td>1.5740741</td>\n<td>1.5740741</td>\n<td>1.0</td>\n<td>0.8555027</td>\n<td>1.0</td>\n<td>0.8555027</td>\n<td>0.0185185</td>\n<td>0.0185185</td>\n<td>57.4074074</td>\n<td>57.4074074</td>\n<td>0.0185185</td></tr>\n<tr><td>2</td>\n<td>0.0235294</td>\n<td>0.8520561</td>\n<td>1.0493827</td>\n<td>1.3117284</td>\n<td>0.6666667</td>\n<td>0.8532494</td>\n<td>0.8333333</td>\n<td>0.8543760</td>\n<td>0.0123457</td>\n<td>0.0308642</td>\n<td>4.9382716</td>\n<td>31.1728395</td>\n<td>0.0201115</td></tr>\n<tr><td>3</td>\n<td>0.0392157</td>\n<td>0.8475783</td>\n<td>1.5740741</td>\n<td>1.4166667</td>\n<td>1.0</td>\n<td>0.8484793</td>\n<td>0.9</td>\n<td>0.8520174</td>\n<td>0.0246914</td>\n<td>0.0555556</td>\n<td>57.4074074</td>\n<td>41.6666667</td>\n<td>0.0448029</td></tr>\n<tr><td>4</td>\n<td>0.0431373</td>\n<td>0.8448949</td>\n<td>1.5740741</td>\n<td>1.4309764</td>\n<td>1.0</td>\n<td>0.8460474</td>\n<td>0.9090909</td>\n<td>0.8514746</td>\n<td>0.0061728</td>\n<td>0.0617284</td>\n<td>57.4074074</td>\n<td>43.0976431</td>\n<td>0.0509757</td></tr>\n<tr><td>5</td>\n<td>0.0509804</td>\n<td>0.8371806</td>\n<td>1.5740741</td>\n<td>1.4529915</td>\n<td>1.0</td>\n<td>0.8388444</td>\n<td>0.9230769</td>\n<td>0.8495315</td>\n<td>0.0123457</td>\n<td>0.0740741</td>\n<td>57.4074074</td>\n<td>45.2991453</td>\n<td>0.0633214</td></tr>\n<tr><td>6</td>\n<td>0.1725490</td>\n<td>0.8308558</td>\n<td>1.4217443</td>\n<td>1.4309764</td>\n<td>0.9032258</td>\n<td>0.8322820</td>\n<td>0.9090909</td>\n<td>0.8373785</td>\n<td>0.1728395</td>\n<td>0.2469136</td>\n<td>42.1744325</td>\n<td>43.0976431</td>\n<td>0.2039028</td></tr>\n<tr><td>7</td>\n<td>0.2078431</td>\n<td>0.8287813</td>\n<td>1.5740741</td>\n<td>1.4552760</td>\n<td>1.0</td>\n<td>0.8287813</td>\n<td>0.9245283</td>\n<td>0.8359186</td>\n<td>0.0555556</td>\n<td>0.3024691</td>\n<td>57.4074074</td>\n<td>45.5276031</td>\n<td>0.2594584</td></tr>\n<tr><td>8</td>\n<td>0.3137255</td>\n<td>0.8270265</td>\n<td>1.5157750</td>\n<td>1.4756944</td>\n<td>0.9629630</td>\n<td>0.8270680</td>\n<td>0.9375</td>\n<td>0.8329315</td>\n<td>0.1604938</td>\n<td>0.4629630</td>\n<td>51.5775034</td>\n<td>47.5694444</td>\n<td>0.4091995</td></tr>\n<tr><td>9</td>\n<td>0.4196078</td>\n<td>0.8145330</td>\n<td>1.4574760</td>\n<td>1.4710973</td>\n<td>0.9259259</td>\n<td>0.8180597</td>\n<td>0.9345794</td>\n<td>0.8291788</td>\n<td>0.1543210</td>\n<td>0.6172840</td>\n<td>45.7475995</td>\n<td>47.1097265</td>\n<td>0.5420151</td></tr>\n<tr><td>10</td>\n<td>0.5019608</td>\n<td>0.7345244</td>\n<td>1.2742504</td>\n<td>1.4388021</td>\n<td>0.8095238</td>\n<td>0.7868364</td>\n<td>0.9140625</td>\n<td>0.8222320</td>\n<td>0.1049383</td>\n<td>0.7222222</td>\n<td>27.4250441</td>\n<td>43.8802083</td>\n<td>0.6039427</td></tr>\n<tr><td>11</td>\n<td>0.6078431</td>\n<td>0.6506194</td>\n<td>1.1076818</td>\n<td>1.3811231</td>\n<td>0.7037037</td>\n<td>0.6979138</td>\n<td>0.8774194</td>\n<td>0.8005766</td>\n<td>0.1172840</td>\n<td>0.8395062</td>\n<td>10.7681756</td>\n<td>38.1123059</td>\n<td>0.6352051</td></tr>\n<tr><td>12</td>\n<td>0.7019608</td>\n<td>0.5119968</td>\n<td>0.7214506</td>\n<td>1.2926754</td>\n<td>0.4583333</td>\n<td>0.5894245</td>\n<td>0.8212291</td>\n<td>0.7722657</td>\n<td>0.0679012</td>\n<td>0.9074074</td>\n<td>-27.8549383</td>\n<td>29.2675357</td>\n<td>0.5633214</td></tr>\n<tr><td>13</td>\n<td>0.8</td>\n<td>0.2965971</td>\n<td>0.6296296</td>\n<td>1.2114198</td>\n<td>0.4</td>\n<td>0.3848365</td>\n<td>0.7696078</td>\n<td>0.7247866</td>\n<td>0.0617284</td>\n<td>0.9691358</td>\n<td>-37.0370370</td>\n<td>21.1419753</td>\n<td>0.4637595</td></tr>\n<tr><td>14</td>\n<td>0.9019608</td>\n<td>0.1808268</td>\n<td>0.2421652</td>\n<td>1.1018519</td>\n<td>0.1538462</td>\n<td>0.2226949</td>\n<td>0.7</td>\n<td>0.6680284</td>\n<td>0.0246914</td>\n<td>0.9938272</td>\n<td>-75.7834758</td>\n<td>10.1851852</td>\n<td>0.2518917</td></tr>\n<tr><td>15</td>\n<td>1.0</td>\n<td>0.1275312</td>\n<td>0.0629630</td>\n<td>1.0</td>\n<td>0.04</td>\n<td>0.1544308</td>\n<td>0.6352941</td>\n<td>0.6176757</td>\n<td>0.0061728</td>\n<td>1.0</td>\n<td>-93.7037037</td>\n<td>0.0</td>\n<td>0.0</td></tr></tbody>\n  </table>\n</div>\n</div></div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-18.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-18 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-18 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-18 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-18 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-18 .h2o-table th,\n#h2o-table-18 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-18 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-18\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Scoring History: </caption>\n    <thead><tr><th></th>\n<th>timestamp</th>\n<th>duration</th>\n<th>number_of_trees</th>\n<th>training_rmse</th>\n<th>training_logloss</th>\n<th>training_auc</th>\n<th>training_pr_auc</th>\n<th>training_lift</th>\n<th>training_classification_error</th>\n<th>validation_rmse</th>\n<th>validation_logloss</th>\n<th>validation_auc</th>\n<th>validation_pr_auc</th>\n<th>validation_lift</th>\n<th>validation_classification_error</th></tr></thead>\n    <tbody><tr><td></td>\n<td>2024-03-04 05:09:30</td>\n<td> 0.005 sec</td>\n<td>0.0</td>\n<td>0.4876573</td>\n<td>0.6685643</td>\n<td>0.5</td>\n<td>0.6104101</td>\n<td>1.0</td>\n<td>0.3895899</td>\n<td>0.4819904</td>\n<td>0.6573905</td>\n<td>0.5</td>\n<td>0.6352941</td>\n<td>1.0</td>\n<td>0.3647059</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.069 sec</td>\n<td>1.0</td>\n<td>0.4647996</td>\n<td>0.6231500</td>\n<td>0.8770884</td>\n<td>0.8935769</td>\n<td>1.5962367</td>\n<td>0.1735016</td>\n<td>0.4611465</td>\n<td>0.6163410</td>\n<td>0.8622727</td>\n<td>0.8809333</td>\n<td>1.4166667</td>\n<td>0.1921569</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.112 sec</td>\n<td>2.0</td>\n<td>0.4449598</td>\n<td>0.5856263</td>\n<td>0.8855151</td>\n<td>0.9047166</td>\n<td>1.6382429</td>\n<td>0.1656151</td>\n<td>0.4439221</td>\n<td>0.5838048</td>\n<td>0.8645958</td>\n<td>0.8905519</td>\n<td>1.5740741</td>\n<td>0.1803922</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.154 sec</td>\n<td>3.0</td>\n<td>0.4288814</td>\n<td>0.5560348</td>\n<td>0.8856511</td>\n<td>0.9047348</td>\n<td>1.6382429</td>\n<td>0.1656151</td>\n<td>0.4293886</td>\n<td>0.5569714</td>\n<td>0.8653591</td>\n<td>0.8907784</td>\n<td>1.5740741</td>\n<td>0.1803922</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.200 sec</td>\n<td>4.0</td>\n<td>0.4153796</td>\n<td>0.5314913</td>\n<td>0.8843643</td>\n<td>0.9040196</td>\n<td>1.6382429</td>\n<td>0.1656151</td>\n<td>0.4171380</td>\n<td>0.5345524</td>\n<td>0.8662220</td>\n<td>0.8913738</td>\n<td>1.5740741</td>\n<td>0.1803922</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.243 sec</td>\n<td>5.0</td>\n<td>0.4032292</td>\n<td>0.5095691</td>\n<td>0.8943445</td>\n<td>0.9113020</td>\n<td>1.6382429</td>\n<td>0.1656151</td>\n<td>0.4055482</td>\n<td>0.5135366</td>\n<td>0.8715651</td>\n<td>0.8985601</td>\n<td>1.5740741</td>\n<td>0.1764706</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.280 sec</td>\n<td>6.0</td>\n<td>0.3920525</td>\n<td>0.4895230</td>\n<td>0.8978805</td>\n<td>0.9151126</td>\n<td>1.6382429</td>\n<td>0.1451104</td>\n<td>0.3977462</td>\n<td>0.4990855</td>\n<td>0.8707686</td>\n<td>0.8928193</td>\n<td>1.5740741</td>\n<td>0.1764706</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.316 sec</td>\n<td>7.0</td>\n<td>0.3835335</td>\n<td>0.4739088</td>\n<td>0.8964211</td>\n<td>0.9122706</td>\n<td>1.6382429</td>\n<td>0.1419558</td>\n<td>0.3886586</td>\n<td>0.4823267</td>\n<td>0.8826497</td>\n<td>0.9066495</td>\n<td>1.5740741</td>\n<td>0.1764706</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.351 sec</td>\n<td>8.0</td>\n<td>0.3753999</td>\n<td>0.4590906</td>\n<td>0.8978334</td>\n<td>0.9140405</td>\n<td>1.6382429</td>\n<td>0.1388013</td>\n<td>0.3842176</td>\n<td>0.4732962</td>\n<td>0.8757135</td>\n<td>0.8959403</td>\n<td>1.5740741</td>\n<td>0.1764706</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.385 sec</td>\n<td>9.0</td>\n<td>0.3680140</td>\n<td>0.4450796</td>\n<td>0.9058783</td>\n<td>0.9250784</td>\n<td>1.6382429</td>\n<td>0.1388013</td>\n<td>0.3778325</td>\n<td>0.4610205</td>\n<td>0.8767755</td>\n<td>0.8990635</td>\n<td>1.5740741</td>\n<td>0.1764706</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.419 sec</td>\n<td>10.0</td>\n<td>0.3625615</td>\n<td>0.4344783</td>\n<td>0.9082635</td>\n<td>0.9262527</td>\n<td>1.6382429</td>\n<td>0.1388013</td>\n<td>0.3730597</td>\n<td>0.4513923</td>\n<td>0.8847073</td>\n<td>0.9074004</td>\n<td>1.5740741</td>\n<td>0.1725490</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.461 sec</td>\n<td>11.0</td>\n<td>0.3572128</td>\n<td>0.4243479</td>\n<td>0.9097176</td>\n<td>0.9271513</td>\n<td>1.6382429</td>\n<td>0.1388013</td>\n<td>0.3704115</td>\n<td>0.4453500</td>\n<td>0.8839772</td>\n<td>0.9070278</td>\n<td>1.5740741</td>\n<td>0.1686275</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.498 sec</td>\n<td>12.0</td>\n<td>0.3522552</td>\n<td>0.4147910</td>\n<td>0.9115536</td>\n<td>0.9287575</td>\n<td>1.6382429</td>\n<td>0.1388013</td>\n<td>0.3675146</td>\n<td>0.4389227</td>\n<td>0.8819196</td>\n<td>0.9063406</td>\n<td>1.5740741</td>\n<td>0.1686275</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.534 sec</td>\n<td>13.0</td>\n<td>0.3485390</td>\n<td>0.4071188</td>\n<td>0.9116582</td>\n<td>0.9287603</td>\n<td>1.6382429</td>\n<td>0.1372240</td>\n<td>0.3646456</td>\n<td>0.4327268</td>\n<td>0.8834462</td>\n<td>0.9056692</td>\n<td>1.5740741</td>\n<td>0.1686275</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.575 sec</td>\n<td>14.0</td>\n<td>0.3453652</td>\n<td>0.4004340</td>\n<td>0.9144148</td>\n<td>0.9330831</td>\n<td>1.6382429</td>\n<td>0.1403785</td>\n<td>0.3618927</td>\n<td>0.4266588</td>\n<td>0.8822846</td>\n<td>0.9008969</td>\n<td>1.5740741</td>\n<td>0.1686275</td></tr>\n<tr><td></td>\n<td>2024-03-04 05:09:31</td>\n<td> 0.610 sec</td>\n<td>15.0</td>\n<td>0.3421510</td>\n<td>0.3938496</td>\n<td>0.9156179</td>\n<td>0.9343343</td>\n<td>1.6382429</td>\n<td>0.1403785</td>\n<td>0.3608975</td>\n<td>0.4235038</td>\n<td>0.8822846</td>\n<td>0.9026781</td>\n<td>1.5740741</td>\n<td>0.1686275</td></tr></tbody>\n  </table>\n</div>\n</div>\n<div style='margin: 1em 0 1em 0;'>\n<style>\n\n#h2o-table-19.h2o-container {\n  overflow-x: auto;\n}\n#h2o-table-19 .h2o-table {\n  /* width: 100%; */\n  margin-top: 1em;\n  margin-bottom: 1em;\n}\n#h2o-table-19 .h2o-table caption {\n  white-space: nowrap;\n  caption-side: top;\n  text-align: left;\n  /* margin-left: 1em; */\n  margin: 0;\n  font-size: larger;\n}\n#h2o-table-19 .h2o-table thead {\n  white-space: nowrap; \n  position: sticky;\n  top: 0;\n  box-shadow: 0 -1px inset;\n}\n#h2o-table-19 .h2o-table tbody {\n  overflow: auto;\n}\n#h2o-table-19 .h2o-table th,\n#h2o-table-19 .h2o-table td {\n  text-align: right;\n  /* border: 1px solid; */\n}\n#h2o-table-19 .h2o-table tr:nth-child(even) {\n  /* background: #F5F5F5 */\n}\n\n</style>      \n<div id=\"h2o-table-19\" class=\"h2o-container\">\n  <table class=\"h2o-table\">\n    <caption>Variable Importances: </caption>\n    <thead><tr><th>variable</th>\n<th>relative_importance</th>\n<th>scaled_importance</th>\n<th>percentage</th></tr></thead>\n    <tbody><tr><td>sex</td>\n<td>228.3824310</td>\n<td>1.0</td>\n<td>0.5599137</td></tr>\n<tr><td>fare</td>\n<td>71.5016937</td>\n<td>0.3130788</td>\n<td>0.1752971</td></tr>\n<tr><td>class</td>\n<td>62.4219093</td>\n<td>0.2733219</td>\n<td>0.1530367</td></tr>\n<tr><td>age</td>\n<td>39.2425575</td>\n<td>0.1718283</td>\n<td>0.0962090</td></tr>\n<tr><td>embark_town</td>\n<td>6.2637715</td>\n<td>0.0274267</td>\n<td>0.0153566</td></tr>\n<tr><td>alone</td>\n<td>0.0762307</td>\n<td>0.0003338</td>\n<td>0.0001869</td></tr></tbody>\n  </table>\n</div>\n</div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n\n[tips]\nUse `model.explain()` to inspect the model.\n--\nUse `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"},"metadata":{}}]}]}